{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from Evaluation import generate_test_subjects\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scipy\n",
    "from scipy.ndimage import zoom\n",
    "from fsl.data.image import Image\n",
    "from fsl.utils.image import resample\n",
    "import torchio as tio\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import os\n",
    "from Preprocess import write_data\n",
    "from utils import plot_images\n",
    "import pandas as pd\n",
    "from skimage.metrics import structural_similarity as ssim_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(slices):\n",
    "    \"\"\" Function to display row of image slices \"\"\"\n",
    "    fig, axes = plt.subplots(len(slices), len(slices[0]))\n",
    "    fig.set_size_inches(15,7.5)\n",
    "    for row in range(len(slices)):\n",
    "        for column in range(len(slices[0])):\n",
    "            axes[row][column].imshow(slices[row][column].T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "\n",
    "def plot_images(inp_np,res_np):\n",
    "    slice_0 = inp_np[int(inp_np.shape[0]/2), :, :]\n",
    "    slice_1 = inp_np[:, int(inp_np.shape[1]/2), :]\n",
    "    slice_2 = inp_np[:, :, int(inp_np.shape[2]/2)]\n",
    "    nslice_0 = res_np[int(res_np.shape[0]/2), :, :]\n",
    "    nslice_1 = res_np[:, int(res_np.shape[1]/2), :]\n",
    "    nslice_2 = res_np[:, :, int(res_np.shape[2]/2)]\n",
    "    show_slices([[slice_0, slice_1, slice_2],\n",
    "                 [nslice_0, nslice_1, nslice_2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_images = os.listdir(os.path.join(\"IXI-T1\",\"Actual_Images\"))\n",
    "target_dir = os.listdir(os.path.join(\"IXI-T1\",\"Compressed_4.0x4.0x1.2\"))\n",
    "pix_dims = [4,4,1.2]\n",
    "for scan in tqdm(actual_images):\n",
    "    fname = os.path.join(\"IXI-T1\",\"Actual_Images\",scan)\n",
    "    img   = Image(fname)\n",
    "    plot_images(img,img)\n",
    "    resample_img = resample.resampleToPixdims(img, pix_dims)\n",
    "    write_data(resample_img[0],scan,resample_img[1],pix_dims,\"IXI-T1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subjects = generate_test_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_subjects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(\"IXI-T1\",\"Actual_Images\",actual_images[0])\n",
    "img   = Image(fname)\n",
    "pix_dims = [4,4,1.2]\n",
    "resample_img = resample.resampleToPixdims(img, pix_dims)\n",
    "print(img.shape,resample_img[0].shape)\n",
    "plot_images(img,resample_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom_factor = np.array(img.shape) / np.array(resample_img[0].shape)\n",
    "zoomed = zoom(resample_img[0], zoom_factor, order=3)\n",
    "\n",
    "plot_images(img,zoomed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the mode based on the method of interpolation required\n",
    "0 - Nearest\n",
    "1 - Bilinear\n",
    "3 - Bicubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "modes = [0,1,3]\n",
    "\n",
    "for mode in modes:\n",
    "    ssim_list = []\n",
    "    for subject in tqdm(test_subjects):\n",
    "        gt,comp = np.squeeze(subject.ground_truth[\"data\"].numpy()),np.squeeze(subject.compressed[\"data\"].numpy())\n",
    "        zoom_factor = np.array(gt.shape) / np.array(comp.shape)\n",
    "        zoomed = zoom(comp, zoom_factor, order=mode)\n",
    "        plot_images(gt,comp)\n",
    "        ssim = ssim_sklearn(zoomed,gt,data_range = gt.max()-gt.min())\n",
    "        ssim_list.append(ssim)\n",
    "    if mode == 0:\n",
    "        results['nearest'] = ssim_list\n",
    "    elif mode == 1:\n",
    "        results['bilinear']= ssim_list\n",
    "    else:\n",
    "        results[\"bicubic\"] = ssim_list\n",
    "\n",
    "with open(\"legacy_methods.pickle\",'wb') as handler:\n",
    "    pickle.dump(results,handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"legacy_methods.pickle\",'rb') as handler:\n",
    "    results = pickle.load(handler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ssims_variable_kernel.data\",'rb') as handler2:\n",
    "    dictionary = pickle.load(handler2)\n",
    "\n",
    "results[\"Densenet\"] = dictionary['Compressed_4.0x4.0x1.2']\n",
    "df = pd.DataFrame.from_dict(results)\n",
    "sns.boxplot(data=df).set_title(\"Super resolution on 4x4x1.2 images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import plot_images\n",
    "import DenseNetModel\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torchio as tio\n",
    "from torchio.transforms import Compose,ZNormalization,RescaleIntensity\n",
    "from torchio import AFFINE,DATA\n",
    "import random\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(slice_list,ssim):\n",
    "    print(\"writing image.......\")\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle(\"ssim : {}\".format(ssim))\n",
    "    ax[0].imshow(slice_list[0], interpolation='nearest', origin=\"lower\", cmap=\"gray\")\n",
    "    ax[0].set_title(\"Original\")\n",
    "    ax[0].set_axis_off()\n",
    "    ax[1].imshow(slice_list[1], interpolation='nearest', origin=\"lower\", cmap=\"gray\")\n",
    "    ax[1].set_title(\"Bicubic\")\n",
    "    ax[1].set_axis_off()\n",
    "    ax[2].imshow(slice_list[2], interpolation='nearest', origin=\"lower\", cmap=\"gray\")\n",
    "    ax[2].set_title(\"Predicted\")\n",
    "    ax[2].set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(sample):\n",
    "    patch_size = 48,48,48\n",
    "    patch_overlap = 4,4,4\n",
    "    model.eval()\n",
    "    grid_sampler = tio.inference.GridSampler(sample,patch_size,patch_overlap)\n",
    "    patch_loader = torch.utils.data.DataLoader(grid_sampler,int(validation_batch_size/4))\n",
    "    aggregator = tio.inference.GridAggregator(grid_sampler,overlap_mode=\"average\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(patch_loader):\n",
    "            inputs = batch[\"compressed\"][DATA].to(\"cuda\")\n",
    "            logits = model(inputs)\n",
    "            location = batch[tio.LOCATION]\n",
    "            aggregator.add_batch(logits,location)\n",
    "    model.train()\n",
    "    result = aggregator.get_output_tensor()\n",
    "    original, compressed = sample.ground_truth[\"data\"].squeeze(), sample.compressed[\"data\"].squeeze()\n",
    "    result = torch.squeeze(result)\n",
    "    original,compressed,result = original.detach().cpu().numpy(),compressed.detach().cpu().numpy(),result.detach().cpu().numpy()\n",
    "    ssim_val = ssim_sklearn(original,result,data_range=original.max()-original.min())\n",
    "    return original,compressed,result,ssim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"Models/DenseNet varying kernel with scale augmentation/denseNet3D_torchIO_patch_32_samples_20_ADAMOptim_50Epochs_BS12_GlorotWeights_SSIM_1511.pth\")\n",
    "model = DenseNetModel.DenseNet(num_init_features=4,growth_rate=6,block_config=(6,6,6)).to(\"cuda\")\n",
    "model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "validation_batch_size = 12\n",
    "test_transform = Compose([RescaleIntensity((0,1))])\n",
    "\n",
    "test_subjects = generate_test_subjects()\n",
    "samples = random.sample(test_subjects[0],5)\n",
    "test_dataset = tio.SubjectsDataset(samples,transform=test_transform)\n",
    "\n",
    "\n",
    "\n",
    "for sample in test_dataset:\n",
    "    original,compressed,result,ssim_val = test_network(sample)\n",
    "    slice_original = (original[:, :, int(original.shape[2] / 2)])\n",
    "    slice_compressed = (compressed[:, :, int(compressed.shape[2] / 2)])\n",
    "    slice_result = (result[:, :, int(result.shape[2] / 2)])\n",
    "    slice_list = [slice_original.T,slice_compressed.T,slice_result.T]\n",
    "    write_image(slice_list,ssim_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = Path(\"IXI-T1/Actual_Images\")\n",
    "ground_paths = sorted(ground_truths.glob('*.nii.gz'))\n",
    "\n",
    "compressed = Path(\"IXI-T1/Compressed\")\n",
    "compressed_paths = sorted(compressed.glob('*.nii.gz'))\n",
    "\n",
    "image_batch = 3\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "subjects=[]\n",
    "transform = Compose([RescaleIntensity((0,1))])\n",
    "\n",
    "for gt,comp in zip(ground_paths,compressed_paths):\n",
    "    \n",
    "    subject = tio.Subject(\n",
    "                    ground_truth = tio.ScalarImage(gt),\n",
    "                    compressed = tio.ScalarImage(comp,dtype=torch.int16)\n",
    "                    )\n",
    "    subjects.append(subject)\n",
    "\n",
    "dataset = tio.SubjectsDataset(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(over='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,subject in enumerate(dataset):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[131].compressed[DATA].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = dataset[131].ground_truth[DATA]\n",
    "gt2 = dataset[130].ground_truth[DATA]\n",
    "\n",
    "print(torch.max(gt),torch.min(gt),gt.dtype)\n",
    "print(torch.max(gt2),torch.min(gt2),gt2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = dataset[131].compressed[DATA]\n",
    "gt2 = dataset[130].compressed[DATA]\n",
    "print(torch.max(gt),torch.min(gt),gt.dtype)\n",
    "print(torch.max(gt2),torch.min(gt2),gt2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity = \"IXI-T1\"\n",
    "ground_dir = os.path.join(intensity, \"Actual_Images\")\n",
    "scans = os.listdir(ground_dir)\n",
    "compressed_dir = os.path.join(intensity, \"Compressed\")\n",
    "target_dir = os.path.join(intensity,\"Interpolated\")\n",
    "\n",
    "for scan in scans:\n",
    "    image_path = os.path.join(compressed_dir,scan)\n",
    "    source_path = os.path.join(ground_dir,scan)\n",
    "    comp_image = tio.ScalarImage(image_path)[DATA]\n",
    "    print(tio.ScalarImage(image_path)[AFFINE])\n",
    "    source_image = tio.ScalarImage(source_path)[DATA]\n",
    "    interpolation = interpolate(comp_image.unsqueeze(dim=0),source_image.squeeze().shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(interpolation.squeeze().numpy(),comp_image.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects,test_subjects,validation_subjects = train_test_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_subjects),len(test_subjects),len(validation_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torchio as tio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchio as tio\n",
    "from torchio import AFFINE,DATA\n",
    "import torchcomplex as torchc\n",
    "from torchio.transforms import Compose,Resample,RescaleIntensity\n",
    "from torchcomplex.nn.functional import interpolate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from fsl.data.image import Image\n",
    "import DenseNetModel\n",
    "from utils import train_test_val_split\n",
    "from pytorch_modelsize import SizeEstimator\n",
    "from torchsummary import summary\n",
    "import UNetModel\n",
    "from MultiScaleExperiment import MultiScale\n",
    "from RRDB import RRDB\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RRDB(nChannels=1,nDenseLayers=6,nInitFeat=6,GrowthRate=12,featureFusion=True,kernel_config=[3,3,3,3]).cuda()\n",
    "# model = MultiScale(nChannels=1,nDenseLayers=6,nInitFeat=6,GrowthRate=12).cuda()\n",
    "summary(model,input_size=(1,64,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetModel.Unet(1,1,8).to(device)\n",
    "summary(model,input_size=(1,64,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RRDB(nChannels=1,nDenseLayers=6,nInitFeat=6,GrowthRate=12).cuda()\n",
    "summary(model,input_size=(1,48,48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiScale(nChannels=1,nDenseLayers=6,nInitFeat=6,GrowthRate=12).cuda()\n",
    "summary(model,input_size=(1,64,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intensity = 'IXI-T2'\n",
    "ground_dir = os.path.join(intensity, \"Actual_Images\")\n",
    "scans = os.listdir(ground_dir)\n",
    "compressed_dir = os.path.join(intensity, \"Compressed\")\n",
    "# target_dir = os.path.join(intensity, \"Interpolated\")\n",
    "for scan in scans:\n",
    "    image_path = os.path.join(compressed_dir, scans[3])\n",
    "    source_path = os.path.join(ground_dir, scans[3])\n",
    "    comp_image = tio.ScalarImage(image_path)[DATA]\n",
    "    source_image = tio.ScalarImage(source_path)[DATA]\n",
    "    print(comp_image.shape, source_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(compressed_dir, scans[3])\n",
    "source_path = os.path.join(ground_dir, scans[3])\n",
    "comp_image = tio.ScalarImage(image_path)[DATA]\n",
    "source_image = tio.ScalarImage(source_path)[DATA]\n",
    "print(comp_image.shape, source_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_image = tio.ScalarImage(image_path)[DATA].squeeze().numpy()\n",
    "source_image = tio.ScalarImage(source_path)[DATA].squeeze().numpy()\n",
    "print(scans[3])\n",
    "\n",
    "plot_images(comp_image,source_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_test_val_split\n",
    "from torchio.transforms import Compose,ZNormalization,RescaleIntensity,RandomNoise\n",
    "import torchio as tio\n",
    "\n",
    "train,test,val = train_test_val_split(\"Train_Test_Val_split.csv\",\"IXI-T1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train),len(test),len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_scale,d_scale = sample.ground_truth.spacing,sample.downsampled.spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_list = {\"Actual_Image\" : f\"{round(o_scale[0],2)}X{round(o_scale[1],2)}X{round(o_scale[2],2)}\",\n",
    "             \"Downsampled\"  : f\"{round(d_scale[0],2)}X{round(d_scale[1],2)}X{round(d_scale[2],2)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = Compose([RescaleIntensity((0,1))])\n",
    "test_dataset = tio.SubjectsDataset(test,transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample.ground_truth.path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocess import interpolate_compressed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_compressed_images(intensity='IXI-T1',fold=\"2d5fold\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "interpolate_compressed_images(intensity='IXI-T1',fold=\"3fold\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "interpolate_compressed_images(intensity='IXI-T1',fold=\"3d5fold\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "interpolate_compressed_images(intensity='IXI-T1',fold=\"4fold\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_compressed_images(intensity='IXI-T2',fold=\"2d5fold\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "interpolate_compressed_images(intensity='IXI-T2',fold=\"3fold\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "interpolate_compressed_images(intensity='IXI-T2',fold=\"3d5fold\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "interpolate_compressed_images(intensity='IXI-T2',fold=\"4fold\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
